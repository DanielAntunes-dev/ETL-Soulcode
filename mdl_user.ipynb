{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMl7hcDiBemT7/CEBtiXULQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DanielAntunes-dev/ETL-Soulcode/blob/main/mdl_user.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas pyspark mysql-connector-python google-cloud-bigquery google-cloud-storage gcsfs pymongo flatten_json"
      ],
      "metadata": {
        "id": "Wb-ByVDSwP9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import mysql.connector\n",
        "from mysql.connector import Error\n",
        "from pyspark.sql import SparkSession\n",
        "from google.cloud import storage\n",
        "from google.api_core.exceptions import Conflict\n",
        "from google.cloud import bigquery\n",
        "from google.colab import auth\n",
        "from google.colab import files\n",
        "from io import BytesIO\n",
        "from pymongo import MongoClient"
      ],
      "metadata": {
        "id": "fInTp89q8kee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, when, from_unixtime\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "spark = SparkSession.builder.appName(\"Processamento de CSV\").getOrCreate()\n",
        "\n",
        "arquivo = 'mdl_user.csv'\n",
        "\n",
        "df = spark.read.csv(arquivo, header=True, inferSchema=True)\n",
        "\n",
        "def substituir_nan(df):\n",
        "    for column in df.columns:\n",
        "        df = df.withColumn(column, when(col(column).isNull(), \"não informado\").otherwise(col(column)))\n",
        "    return df\n",
        "\n",
        "df = substituir_nan(df)\n",
        "\n",
        "def tratar_campos_para_unix_timestamp(df, colunas):\n",
        "    for coluna in colunas:\n",
        "        df = df.withColumn(\n",
        "            coluna,\n",
        "            F.when(F.col(coluna) != 0, F.from_unixtime(F.col(coluna)))\n",
        "             .otherwise(F.col(coluna))\n",
        "        )\n",
        "    return df\n",
        "\n",
        "colunas_para_tratar = [\"firstaccess\", \"lastaccess\", \"lastlogin\", \"currentlogin\", \"timecreated\", \"timemodified\"]\n",
        "df = tratar_campos_para_unix_timestamp(df, colunas_para_tratar)\n",
        "\n",
        "df.show(truncate=False)"
      ],
      "metadata": {
        "id": "sNLZCECQ8mZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pandas_gbq import to_gbq\n",
        "\n",
        "table_id = 'mdl_user'\n",
        "dataset_id = 'dados_estudos'\n",
        "project_id = 'cryptic-cache-434413-r6'\n",
        "\n",
        "# Converter o DataFrame Spark para pandas\n",
        "df_pandas = df.toPandas()\n",
        "\n",
        "# Definir as colunas de timestamp\n",
        "timestamp_columns = [\"firstaccess\", \"lastaccess\", \"lastlogin\", \"currentlogin\", \"timecreated\", \"timemodified\"]\n",
        "\n",
        "# Formato de data\n",
        "date_format = \"%Y-%m-%d %H:%M:%S\"\n",
        "\n",
        "# Converter as colunas de timestamp para datetime\n",
        "for col in timestamp_columns:\n",
        "    if col in df_pandas.columns:\n",
        "        df_pandas[col] = pd.to_datetime(df_pandas[col], format=date_format, errors='coerce')\n",
        "\n",
        "# Converter a coluna 'id' para INTEGER\n",
        "if 'id' in df_pandas.columns:\n",
        "    df_pandas['id'] = pd.to_numeric(df_pandas['id'], errors='coerce').astype('Int64')\n",
        "\n",
        "# Referência da tabela\n",
        "table_ref = f'{project_id}.{dataset_id}.{table_id}'\n",
        "\n",
        "# Carregar o DataFrame pandas para o BigQuery\n",
        "to_gbq(df_pandas, destination_table=table_ref, project_id=project_id, if_exists='replace')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iN7v02Z_8pTe",
        "outputId": "e9c08e5d-9744-46f3-fa07-fa2128759c34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 6944.21it/s]\n"
          ]
        }
      ]
    }
  ]
}